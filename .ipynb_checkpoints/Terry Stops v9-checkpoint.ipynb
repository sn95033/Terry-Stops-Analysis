{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seattle Terry Stops Final Project Submission\n",
    "\n",
    "* Student name: Rebecca Mih\n",
    "* Student pace: Part Time Online\n",
    "* Scheduled project review date/time: May 5, 2020 12:00pm\n",
    "* Instructor name: James Irving\n",
    "* Blog post URL: https://github.com/sn95033/Terry-Stops-Analysis\n",
    "\n",
    "\n",
    "* **Data Source:**  https://www.kaggle.com/city-of-seattle/seattle-terry-stops\n",
    "\n",
    "    * Date of last update to the datasource: April 15, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src= \"Seattle Police Dept.jpg\"\n",
    "           width=200\"/>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Background\n",
    "\n",
    "https://caselaw.findlaw.com/us-supreme-court/392/1.html\n",
    "\n",
    "This data represents records of police reported stops under Terry v. Ohio, 392 U.S. 1 (1968). Each row represents a unique stop.\n",
    "\n",
    " A Terry stop is a seizure under both state and federal law. A Terry stop is\n",
    "defined in policy as a brief, minimally intrusive seizure of a subject based upon\n",
    "**articulable reasonable suspicion (ARS) in order to investigate possible criminal activity.**\n",
    "The stop can apply to people as well as to vehicles. The subject of a Terry stop is\n",
    "**not** free to leave.\n",
    "\n",
    "Section 6.220 of the Seattle Police Department (SPD) Manual defines Reasonable Suspicion as:\n",
    "Specific, objective, articulable facts which, taken together with rational inferences, would\n",
    "create a  **well-founded suspicion that there is a substantial possibility that a subject has\n",
    "engaged, is engaging or is about to engage in criminal conduct.**\n",
    "\n",
    "- Each record contains perceived demographics of the subject, as reported by the officer making the stop and officer demographics as reported to the Seattle Police Department, for employment purposes.\n",
    "- Where available, data elements from the associated Computer Aided Dispatch (CAD) event (e.g. Call Type, Initial Call Type, Final Call Type) are included.\n",
    "\n",
    "\n",
    "## Notes on Concealed Weapons in the State of Washington\n",
    "\n",
    "WHAT ARE WASHINGTON’S CONCEALED CARRY LAWS?\n",
    "Open carry of a firearm is lawful without a permit in the state of Washington except, according to the law, “under circumstances, and at a time and place that either manifests an intent to intimidate another or that warrants alarm for the safety of other persons.”\n",
    "\n",
    "**However, open carry of a loaded handgun in a vehicle is legal only with a concealed pistol license. Open carry of a loaded long gun in a vehicle is illegal.**\n",
    "\n",
    "The criminal charge of “carrying a concealed firearm” happens in this state when someone carries a concealed firearm **without a concealed pistol license**. It does not matter if the weapon was discovered in the defendant’s home, vehicle, or on his or her person.\n",
    "\n",
    "## Objectives\n",
    "### Target:\n",
    "\n",
    "   * Build a classifier which predicts Terry Stops that lead to Arrest (Binary Classification), given information about the presence of weapons, the time of day of the call, etc.  \n",
    "    \n",
    "### Features:\n",
    "   * Report Date\n",
    "   * Report time\n",
    "   * Initial Call Type\n",
    "   * Final Call Type\n",
    "   * Call Type\n",
    "   * Stop Resolution\n",
    "   * Weapon type\n",
    "   * Officer Squad\n",
    "   * Officer Year of Birth\n",
    "   * Perceived Age of subject\n",
    "   * Race of officer\n",
    "   * Perceived Race of subject\n",
    "   * Gender of officer\n",
    "   * Perceived Gender of subject\n",
    "   \n",
    "### Engineered Features:\n",
    "    * Day of the week\n",
    "    * Monthly cadence\n",
    "    * Precinct\n",
    "    * Watch \n",
    "    * Officer Age\n",
    "    \n",
    " ### Experiments:\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Definition of Features Provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Column Names and descriptions provided in the SPD dataset  <br>\n",
    "* **Subject Age Group**\t\n",
    "Subject Age Group (10 year increments) as reported by the officer. <br><br>\n",
    "\n",
    "* **Subject ID**\t\n",
    "Key, generated daily, identifying unique subjects in the dataset using a character to character match of first name and last name. \"Null\" values indicate an \"anonymous\" or \"unidentified\" subject. Subjects of a Terry Stop are not required to present identification.  **Not Used** <br><br>\n",
    "\n",
    "* **GO / SC Num**\n",
    "General Offense or Street Check number, relating the Terry Stop to the parent report. This field may have a one to many relationship in the data. **Not Used** <br><br>\n",
    "\n",
    "* **Terry Stop ID**\n",
    "Key identifying unique Terry Stop reports.  **Not Used**\n",
    "<br><br>\n",
    "\n",
    "* **Stop Resolution**\n",
    "Resolution of the stop**One hot encoding** <br><br>\n",
    "\n",
    "* **Weapon Type**\t\n",
    "Type of weapon, if any, identified during a search or frisk of the subject. Indicates \"None\" if no weapons was found.  <br><br>\n",
    "\n",
    "* **Officer ID**\t\n",
    "Key identifying unique officers in the dataset.\n",
    "**Not Used** <br><br>\n",
    "\n",
    "* **Officer YOB**\t\n",
    "Year of birth, as reported by the officer.  <br><br>\n",
    "\n",
    "* **Officer Gender**\t\n",
    "Gender of the officer, as reported by the officer.\n",
    " <br><br>\n",
    "\n",
    "* **Officer Race**\t\n",
    "Race of the officer, as reported by the officer. <br><br>\n",
    "\n",
    "* **Subject Perceived Race**\t\n",
    "Perceived race of the subject, as reported by the officer. <br><br>\n",
    "\n",
    "* **Subject Perceived Gender**\t\n",
    "Perceived gender of the subject, as reported by the officer. <br><br>\n",
    "\n",
    "* **Reported Date**\t\n",
    "Date the report was filed in the Records Management System (RMS). Not necessarily the date the stop occurred but generally within 1 day.  <br><br>\n",
    "\n",
    "* **Reported Time**\t\n",
    "Time the stop was reported in the Records Management System (RMS). Not the time the stop occurred but generally within 10 hours.  <br><br>\n",
    "\n",
    "* **Initial Call Type**\t\n",
    "Initial classification of the call as assigned by 911.  <br><br>\n",
    "\n",
    "* **Final Call Type**\t\n",
    "Final classification of the call as assigned by the primary officer closing the event.  <br><br>\n",
    "\n",
    "* **Call Type**\t\n",
    "How the call was received by the communication center.\n",
    "\n",
    "* **Officer Squad**\t\n",
    "Functional squad assignment (not budget) of the officer as reported by the Data Analytics Platform (DAP). <br><br>\n",
    "\n",
    "* **Arrest Flag**\t\n",
    "Indicator of whether a \"physical arrest\" was made, of the subject, during the Terry Stop. Does not necessarily reflect a report of an arrest in the Records Management System (RMS). <br><br>\n",
    "\n",
    "* **Frisk Flag**\t\n",
    "Indicator of whether a \"frisk\" was conducted, by the officer, of the subject, during the Terry Stop. <br><br>\n",
    "\n",
    "* **Precinct**\t\n",
    "Precinct of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred. <br><br>\n",
    "\n",
    "* **Sector**\t\n",
    "Sector of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred. <br><br>\n",
    "\n",
    "* **Beat**\t\n",
    "Beat of the address associated with the underlying Computer Aided Dispatch (CAD) event. Not necessarily where the Terry Stop occurred. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analysis Workflow (OSEMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. **Obtain and Pre-process**\n",
    "    - [x] Import data\n",
    "    - [x] Remove unused columns\n",
    "    - [x] Check data size, NaNs, and # of non-null values which are not valid data \n",
    "    - [x] Clean up missing values by imputing values or dropping\n",
    "    - [x] Replace ? or other non-valid data by imputing values or dropping data\n",
    "    - [x] Check for duplicates and remove if appropriate\n",
    "    - [x] Change datatypes of columns as appropriate \n",
    "    - [x] Note which features are continuous and which are categorical<br><br>\n",
    "\n",
    "2. **Data Scoping**\n",
    "     - [x] Use value_counts() to identify dummy categories such as \"-\", or \"?\" for later re-mapping\n",
    "     - [x] Identify most common word data\n",
    "     - [x] Decide on which columns (features) to keep for further feature engineering\n",
    "   \n",
    "3. **Transformation of data (Feature Engineering)**\n",
    "    - [x] Re-bin categories to reduce noise\n",
    "    - [x] Re-map categories as needed\n",
    "    - [x] Engineer text data to extract common word information\n",
    "    - [x] Transform categoricals using 1-hot encoding or label encoding/\n",
    "    - [x] Perform log transformations on continuous variables (if applicable)\n",
    "    - [x] Normalize continuous variables\n",
    "    - [x] Use re-sampling if needed to balance the dataset <br> <br>\n",
    "    \n",
    "4. **Further Feature Selection**\n",
    "     - [x] Use .describe() and .hist() histograms\n",
    "     - [x] Identify outliers (based on auto-scaling of plots) and remove or inpute as needed\n",
    "     - [x] Perform visualizations on key features to understand  \n",
    "     - [x] Inspect feature correlations (Pearson correlation) to identify co-linear features**<br><br>\n",
    "\n",
    "5.  **Create a Vanilla Machine Learning Model**\n",
    "    - [x] Split into train and test data \n",
    "    - [x] Run the model\n",
    "    - [x] Review Quality indicators of the model <br><br>\n",
    "\n",
    "6. **Run more advanced models**\n",
    "    - [x] Compare the model quality\n",
    "    - [x] Choose one or more models for grid searching <br><br>\n",
    "    \n",
    "7. **Revise data inputs if needed to improve quality indicators**\n",
    "    - [x] By adding created features, and removing colinear features\n",
    "    - [x] By improving unbalanced datasets through oversampling or undersampling\n",
    "    - [x] by removing outliers through filters\n",
    "    - [x] through use of subject matter knowledge <br><br>\n",
    "    \n",
    "8. **Write the Report**\n",
    "    - [X] Explain key findings and recommended next steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Obtain and Pre-Process the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Obtain and Pre-process**\n",
    "    - [x] Import data\n",
    "    - [x] Remove unused columns\n",
    "    - [x] Check data size, NaNs, and # of non-null values which are not valid data \n",
    "    - [x] Clean up missing values by imputing values or dropping\n",
    "    - [x] Replace ? or other non-valid data by imputing values or dropping data\n",
    "    - [x] Check for duplicates and remove if appropriate\n",
    "    - [x] Change datatypes of columns as appropriate \n",
    "    - [x] Decide the target column, if not already decided\n",
    "    - [x] Determine if some data is not relevent to the question (drop columns or rows)\n",
    "    - [x] Note which features which will need to be re-mapped or encoded \n",
    "    - [x] Note which features might require feature engineering (example - date, time) <br><br>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsds_1007219  v0.7.21 loaded.  Read the docs: https://fsds.readthedocs.io/en/latest/ \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8\" ><caption>Loaded Packages and Handles</caption><thead>    <tr>        <th class=\"col_heading level0 col0\" >Handle</th>        <th class=\"col_heading level0 col1\" >Package</th>        <th class=\"col_heading level0 col2\" >Description</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row0_col0\" class=\"data row0 col0\" >dp</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row0_col1\" class=\"data row0 col1\" >IPython.display</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row0_col2\" class=\"data row0 col2\" >Display modules with helpful display and clearing commands.</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row1_col0\" class=\"data row1 col0\" >fs</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row1_col1\" class=\"data row1 col1\" >fsds_100719</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row1_col2\" class=\"data row1 col2\" >Custom data science bootcamp student package</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row2_col0\" class=\"data row2 col0\" >mpl</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row2_col1\" class=\"data row2 col1\" >matplotlib</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row2_col2\" class=\"data row2 col2\" >Matplotlib's base OOP module with formatting artists</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row3_col0\" class=\"data row3 col0\" >plt</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row3_col1\" class=\"data row3 col1\" >matplotlib.pyplot</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row3_col2\" class=\"data row3 col2\" >Matplotlib's matlab-like plotting module</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row4_col0\" class=\"data row4 col0\" >np</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row4_col1\" class=\"data row4 col1\" >numpy</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row4_col2\" class=\"data row4 col2\" >scientific computing with Python</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row5_col0\" class=\"data row5 col0\" >pd</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row5_col1\" class=\"data row5 col1\" >pandas</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row5_col2\" class=\"data row5 col2\" >High performance data structures and tools</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row6_col0\" class=\"data row6 col0\" >sns</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row6_col1\" class=\"data row6 col1\" >seaborn</td>\n",
       "                        <td id=\"T_a172f5e2_93b3_11ea_91c5_5800e3d0a9a8row6_col2\" class=\"data row6 col2\" >High-level data visualization library based on matplotlib</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x232390e8080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Pandas .iplot() method activated.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U fsds_100719\n",
    "from fsds_100719.imports import *\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import copy\n",
    "import sklearn\n",
    "import math\n",
    "import datetime\n",
    "#import plotly.express as px\n",
    "#import plotly.graphy_objects as go\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#!pip3 install xgboost\n",
    "import xgboost as xbg\n",
    "from xgboost import XGBRFClassifier,XGBClassifier\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.set_option('display.max_columns',0)\n",
    "pd.set_option('display.max_info_rows',200)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function which evaluates the model, and returns\n",
    "def evaluate_model(y_true, y_pred,X_true,clf,\n",
    "                    cm_kws=dict(cmap=\"YlGnBu\",normalize='true'),figsize=(10,4),plot_roc_auc=True, \n",
    "                    expt_name='Model'):\n",
    "    \n",
    "    '''Function which evaluates each model, stores the result and figures\n",
    "    Inputs: \n",
    "        y_true: target output of the model based on test data\n",
    "        y_pred: target input to the model based on train data\n",
    "        X_true: result output of the model based on test data\n",
    "        \n",
    "        clf:  classification learning function utilized for the model (examples: xgb-rf, Catboost)\n",
    "        \n",
    "        cm_kws: keyword settings for plotting and normalization\n",
    "                Defaults: cmap=\"Blues\", normalize = \"true\"\n",
    "                figsize: size of the plot,  default=(10,10)\n",
    "\n",
    "        expt_name: Pass in the experiment name, so that the saved feature importance image will be unique\n",
    "                  default = A  \n",
    "    Outputs:  \n",
    "              result_df: dataframe which contains the classification metrics \n",
    "                (precision, recall, f1-score, weighted average, accuracy)\n",
    "                \n",
    "              df_important: The top 5 feature importances, the accuracy and AUC\n",
    "    \n",
    "    Saves:   roc_auc plot - plot of AUC for the model\n",
    "             Feature importance plot\n",
    "    '''\n",
    "    \n",
    "    ## Get the Accuracy metrics\n",
    "    \n",
    "    accuracy_result = round(accuracy_score(y_true, y_pred),3)\n",
    "    metrics_report = metrics.classification_report(y_true,y_pred, \n",
    "                                            target_names = ['Not Arrested', 'Arrested'],\n",
    "                                           output_dict=True)\n",
    "    print('Model Name = ', expt_name)\n",
    "    print(f'Accuracy Score = {accuracy_result:.3}')\n",
    "\n",
    "    ## Save scores into the results dataframe\n",
    "    result_df = pd.DataFrame(metrics_report).transpose()\n",
    "    result_df.drop(labels='accuracy',axis = 0, inplace=True)\n",
    "    #result_df.drop(labels='support', axis = 1, inplace=True)\n",
    "    # Swap Rows  https://stackoverflow.com/questions/55439469/swapping-two-rows-together-with-index-within-the-same-pandas-dataframe\n",
    "    # result_df.iloc[np.r_[0:len(result_df) -2, -1, -2]] \n",
    "\n",
    "    result_df.rename(index= {'weighted avg':'Weighted Avg', 'accuracy':'Accuracy',\n",
    "                            'macro avg': 'Macro Avg',}, inplace=True)\n",
    "\n",
    "    result_df.rename(columns = {'precision': 'Precision', 'recall':'Recall', \n",
    "                                'f1-score':'F1 Score','support':'Support'}, inplace=True)\n",
    "    display(result_df)\n",
    "\n",
    "    \n",
    "    if plot_roc_auc:\n",
    "        num_cols=2\n",
    "    else:\n",
    "        num_cols=1\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=figsize,ncols=num_cols)\n",
    "  \n",
    "    \n",
    "    if not isinstance(ax,np.ndarray):\n",
    "        ax=[ax]\n",
    "        \n",
    "    try:\n",
    "        metrics.plot_confusion_matrix(clf,X_true,y_true,ax=ax[0],**cm_kws)\n",
    "        ax[0].grid(False)\n",
    "        ax[0].set(title='Confusion Matrix')\n",
    "        plt.savefig((\"Confusion Matrix {}.png\").format(expt_name))\n",
    "    except:\n",
    "            print('Confusion Matrix Not Working')\n",
    "        \n",
    "    \n",
    "    if plot_roc_auc:\n",
    "        try:\n",
    "            y_score = clf.predict_proba(X_true)[:,1]\n",
    "\n",
    "            fpr,tpr,thresh = metrics.roc_curve(y_true,y_score)\n",
    "            roc_auc = round(metrics.auc(fpr,tpr),3)\n",
    "            \n",
    "            ax[1].plot(fpr,tpr,color='teal',label=f'ROC Curve (AUC={roc_auc})')\n",
    "            ax[1].plot([0,1],[0,1],ls=':')\n",
    "            ax[1].legend()\n",
    "            ax[1].grid(b=False)\n",
    "            ax[1].set(ylabel='True Positive Rate',xlabel='False Positive Rate',\n",
    "                  title='Receiver operating characteristic (ROC) Curve')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig((\"ROC Curve {}.png\").format(expt_name))  \n",
    "            print(\"AUC = \", roc_auc)\n",
    "    \n",
    "        except:\n",
    "            print('ROC-AUC not working')\n",
    "    try: \n",
    "        df_important = plot_importance(clf, expt_name = expt_name)\n",
    "        df_important = df_important.sort_values(ascending=False).head()\n",
    "        df_important[\"Accuracy\"] = accuracy_result\n",
    "        df_important['AUC'] = roc_auc\n",
    "        df_important = df_important.reset_index()\n",
    "        df_important = df_important.rename(columns = {'index':'Description', 0:expt_name})\n",
    "       \n",
    "      \n",
    "    except:\n",
    "        df_important = None\n",
    "        print('importance plotting not working')\n",
    "    \n",
    "    return result_df, df_important\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_importance(tree, top_n=20,figsize=(10,10),expt_name='Model'):\n",
    "    \n",
    "    '''Feature Selection tool, which plots the feature importance based on results\n",
    "    \n",
    "    Inputs:\n",
    "      tree: classification learning function utilized\n",
    "      top_n: top n features contributing to the model, default = 20\n",
    "      figsize:  size of the plot,  default=(10,10)\n",
    "      expt_name: Pass in the experiment name, so that the saved feature importance image will be unique\n",
    "                  default = Model\n",
    "                  \n",
    "    Returns: df_importance - series of the model features sorted by importance\n",
    "    Saves:  Feature importance figure as  \"Feature expt_name.png\", Default expt_name = \"Model\" '''\n",
    "    \n",
    "    df_importance = pd.Series(tree.feature_importances_,index=X_train.columns).sort_values(ascending=True)\n",
    "    df_importance.tail(top_n).plot(kind='barh',figsize=figsize, color='teal')\n",
    "    plt.savefig((\"Feature {}.png\").format(expt_name))\n",
    "    #plt.savefig(\"Feature Importance 2.png\", transparent = True)\n",
    "    \n",
    "    \n",
    "    return df_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_call_types(df_to_clean, col_name, new_col):\n",
    "    '''Transform Call Type text into a single identifier\n",
    "    \n",
    "    Inputs:  df,  col_name -  column which has the Call type,  and a new column name\n",
    "    \n",
    "    Outputs: The dataframe with a new column name, and a dictionary which can be used for .map()'''\n",
    "    idx = df_to_clean[col_name] == '-' # Create an index of the true and false values for the condition == '-'\n",
    "    df_to_clean.loc[idx, col_name] = 'Unknown'\n",
    "    column_series = df_to_clean[col_name]\n",
    "    df_to_clean[new_col] = column_series.apply(lambda x:x.replace('--','').split('-')[0].strip())\n",
    "    #df_to_clean[new_col].value_counts(dropna=False).sort_index()\n",
    "    #df_to_clean.isna().sum()\n",
    "    df_to_clean[new_col] = df_to_clean[new_col].str.extract(r'(\\w+)')\n",
    "    df_to_clean[new_col] = df_to_clean[new_col].str.lower()\n",
    "    last_map = df_to_clean[new_col].value_counts().to_dict()\n",
    "    return last_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Terry_Stops.csv',low_memory=False)\n",
    "df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop Columns which contain IDs, which are not useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Subject ID', 'GO / SC Num', 'Terry Stop ID', 'Officer ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()\n",
    "# After dropping some of the columns, some rows appear to be duplicated.\n",
    "# However, since the date and time of the incident are NOT exact (i.e. the date could be 24 hours later, and the\n",
    "# time could be 10 hours later), it's possible to get some that are similar on different consecutive dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Subject Age Group', 'Stop Resolution', 'Weapon Type', 'Officer YOB',\n",
      "       'Officer Gender', 'Officer Race', 'Subject Perceived Race',\n",
      "       'Subject Perceived Gender', 'Reported Date', 'Reported Time',\n",
      "       'Initial Call Type', 'Final Call Type', 'Call Type', 'Officer Squad',\n",
      "       'Arrest Flag', 'Frisk Flag', 'Precinct', 'Sector', 'Beat'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "col_names = df.columns\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41104, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n",
    "\n",
    "# The rationale for this is to understand how big the dataset is,  how many features are contained in the data\n",
    "# This helps with planning for function vs lambda functions,  and whether certain kinds of visualizations will be feasible\n",
    "# for the analysis (with my computer hardware).  With compute limitations, types of correlation plots cause the kernal to die,\n",
    "# if there are more than 11 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "* df.isna().sum()\n",
    "\n",
    "isna().sum() determines how many data are missing from a given feature\n",
    "\n",
    "* df.info() \n",
    "\n",
    "df.info() helps you determine if there missing values or datatypes that need to be modified\n",
    "\n",
    "* Handy alternate checks if needed **\n",
    "    - [x] df.isna().any()\n",
    "    - [x] df.isnull().any()\n",
    "    - [x] df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject Age Group             0\n",
       "Stop Resolution               0\n",
       "Weapon Type                   0\n",
       "Officer YOB                   0\n",
       "Officer Gender                0\n",
       "Officer Race                  0\n",
       "Subject Perceived Race        0\n",
       "Subject Perceived Gender      0\n",
       "Reported Date                 0\n",
       "Reported Time                 0\n",
       "Initial Call Type             0\n",
       "Final Call Type               0\n",
       "Call Type                     0\n",
       "Officer Squad               535\n",
       "Arrest Flag                   0\n",
       "Frisk Flag                    0\n",
       "Precinct                      0\n",
       "Sector                        0\n",
       "Beat                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Officer Squad'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Findings from isna().sum() *\n",
    "* Officer Squad has 535 missing data (1.3% of the data)\n",
    "    * Impute \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41104 entries, 0 to 41103\n",
      "Data columns (total 19 columns):\n",
      " #   Column                    Dtype \n",
      "---  ------                    ----- \n",
      " 0   Subject Age Group         object\n",
      " 1   Stop Resolution           object\n",
      " 2   Weapon Type               object\n",
      " 3   Officer YOB               int64 \n",
      " 4   Officer Gender            object\n",
      " 5   Officer Race              object\n",
      " 6   Subject Perceived Race    object\n",
      " 7   Subject Perceived Gender  object\n",
      " 8   Reported Date             object\n",
      " 9   Reported Time             object\n",
      " 10  Initial Call Type         object\n",
      " 11  Final Call Type           object\n",
      " 12  Call Type                 object\n",
      " 13  Officer Squad             object\n",
      " 14  Arrest Flag               object\n",
      " 15  Frisk Flag                object\n",
      " 16  Precinct                  object\n",
      " 17  Sector                    object\n",
      " 18  Beat                      object\n",
      "dtypes: int64(1), object(18)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated(keep = False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use value_counts() - inspect for dummy variables, and determine next steps for data cleaning\n",
    "\n",
    "1. Rationale:  This analysis is useful for flushing out missing values in the form of question marks, dashes or other symbols or dummy variables <br><br>\n",
    "\n",
    "2.  It also gives a preliminary view of the number and distribution of categories in each feature, albeit by numbers rather than graphics <br><br>\n",
    "\n",
    "3. For text data, value_counts serves as a preliminary investigation of the common important word data <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject Age Group \n",
      " 26 - 35         13615\n",
      "36 - 45          8547\n",
      "18 - 25          8509\n",
      "46 - 55          5274\n",
      "56 and Above     1996\n",
      "1 - 17           1876\n",
      "-                1287\n",
      "Name: Subject Age Group, dtype: int64 \n",
      "\n",
      "Stop Resolution \n",
      " Field Contact               16287\n",
      "Offense Report              13976\n",
      "Arrest                       9957\n",
      "Referred for Prosecution      728\n",
      "Citation / Infraction         156\n",
      "Name: Stop Resolution, dtype: int64 \n",
      "\n",
      "Weapon Type \n",
      " None                                 32565\n",
      "-                                     6213\n",
      "Lethal Cutting Instrument             1482\n",
      "Knife/Cutting/Stabbing Instrument      308\n",
      "Handgun                                262\n",
      "Firearm Other                          100\n",
      "Club, Blackjack, Brass Knuckles         49\n",
      "Blunt Object/Striking Implement         37\n",
      "Firearm                                 18\n",
      "Firearm (unk type)                      15\n",
      "Other Firearm                           13\n",
      "Mace/Pepper Spray                       12\n",
      "Club                                     9\n",
      "Rifle                                    5\n",
      "None/Not Applicable                      4\n",
      "Taser/Stun Gun                           4\n",
      "Shotgun                                  3\n",
      "Automatic Handgun                        2\n",
      "Brass Knuckles                           1\n",
      "Fire/Incendiary Device                   1\n",
      "Blackjack                                1\n",
      "Name: Weapon Type, dtype: int64 \n",
      "\n",
      "Officer YOB \n",
      " 1986    2930\n",
      "1987    2600\n",
      "1984    2558\n",
      "1991    2356\n",
      "1985    2331\n",
      "1992    2033\n",
      "1990    1892\n",
      "1988    1831\n",
      "1989    1753\n",
      "1982    1733\n",
      "1983    1587\n",
      "1979    1351\n",
      "1981    1268\n",
      "1971    1177\n",
      "1993    1113\n",
      "1978    1043\n",
      "1977     933\n",
      "1976     904\n",
      "1973     856\n",
      "1980     754\n",
      "1995     753\n",
      "1967     684\n",
      "1994     591\n",
      "1968     583\n",
      "1970     544\n",
      "1974     522\n",
      "1969     511\n",
      "1975     475\n",
      "1962     447\n",
      "1965     403\n",
      "1972     394\n",
      "1964     391\n",
      "1996     252\n",
      "1963     227\n",
      "1958     218\n",
      "1966     216\n",
      "1961     202\n",
      "1959     174\n",
      "1997     170\n",
      "1960     154\n",
      "1954      43\n",
      "1957      41\n",
      "1953      32\n",
      "1955      21\n",
      "1956      16\n",
      "1948      11\n",
      "1900       9\n",
      "1952       9\n",
      "1949       5\n",
      "1946       2\n",
      "1951       1\n",
      "Name: Officer YOB, dtype: int64 \n",
      "\n",
      "Officer Gender \n",
      " M    36504\n",
      "F     4593\n",
      "N        7\n",
      "Name: Officer Gender, dtype: int64 \n",
      "\n",
      "Officer Race \n",
      " White                            31805\n",
      "Hispanic or Latino                2255\n",
      "Two or More Races                 2158\n",
      "Black or African American         1674\n",
      "Asian                             1563\n",
      "Not Specified                      912\n",
      "Nat Hawaiian/Oth Pac Islander      419\n",
      "American Indian/Alaska Native      309\n",
      "Unknown                              9\n",
      "Name: Officer Race, dtype: int64 \n",
      "\n",
      "Subject Perceived Race \n",
      " White                                        20192\n",
      "Black or African American                    12243\n",
      "Unknown                                       2073\n",
      "Hispanic                                      1684\n",
      "-                                             1422\n",
      "Asian                                         1278\n",
      "American Indian or Alaska Native              1224\n",
      "Multi-Racial                                   809\n",
      "Other                                          152\n",
      "Native Hawaiian or Other Pacific Islander       27\n",
      "Name: Subject Perceived Race, dtype: int64 \n",
      "\n",
      "Subject Perceived Gender \n",
      " Male                                                         32049\n",
      "Female                                                        8468\n",
      "Unable to Determine                                            326\n",
      "-                                                              253\n",
      "Unknown                                                          7\n",
      "Gender Diverse (gender non-conforming and/or transgender)        1\n",
      "Name: Subject Perceived Gender, dtype: int64 \n",
      "\n",
      "Reported Date \n",
      " 2015-10-01T00:00:00    101\n",
      "2015-09-29T00:00:00     66\n",
      "2015-05-28T00:00:00     57\n",
      "2015-07-18T00:00:00     55\n",
      "2019-04-26T00:00:00     54\n",
      "                      ... \n",
      "2015-05-06T00:00:00      1\n",
      "2015-05-13T00:00:00      1\n",
      "2015-03-28T00:00:00      1\n",
      "2015-05-10T00:00:00      1\n",
      "2015-04-28T00:00:00      1\n",
      "Name: Reported Date, Length: 1860, dtype: int64 \n",
      "\n",
      "Reported Time \n",
      " 19:18:00    51\n",
      "03:13:00    50\n",
      "02:56:00    50\n",
      "03:09:00    50\n",
      "19:02:00    49\n",
      "            ..\n",
      "15:43:10     1\n",
      "09:59:42     1\n",
      "09:37:08     1\n",
      "21:59:44     1\n",
      "09:52:31     1\n",
      "Name: Reported Time, Length: 7644, dtype: int64 \n",
      "\n",
      "Initial Call Type \n",
      " -                                                 12743\n",
      "SUSPICIOUS PERSON, VEHICLE OR INCIDENT             2492\n",
      "SUSPICIOUS STOP - OFFICER INITIATED ONVIEW         2489\n",
      "DISTURBANCE, MISCELLANEOUS/OTHER                   2116\n",
      "ASLT - IP/JO - WITH OR W/O WPNS (NO SHOOTINGS)     1714\n",
      "                                                  ...  \n",
      "KNOWN KIDNAPPNG                                       1\n",
      "MISSING - (ALZHEIMER, ENDANGERED, ELDERLY)            1\n",
      "DEMONSTRATIONS                                        1\n",
      "VICE - PORNOGRAPHY                                    1\n",
      "PHONE - OBSCENE OR NUISANCE PHONE CALLS               1\n",
      "Name: Initial Call Type, Length: 161, dtype: int64 \n",
      "\n",
      "Final Call Type \n",
      " -                                                     12743\n",
      "--SUSPICIOUS CIRCUM. - SUSPICIOUS PERSON               2991\n",
      "--PROWLER - TRESPASS                                   2672\n",
      "--DISTURBANCE - OTHER                                  2318\n",
      "--ASSAULTS, OTHER                                      1967\n",
      "                                                      ...  \n",
      "MVC - NON INJURY, BLOCKING                                1\n",
      "ASSIST PUBLIC - NO WELFARE CHK OR DV ORDER SERVICE        1\n",
      "MVC - HIT AND RUN (NON INJURY), INCLUDES IP/JO            1\n",
      "THEFT OF SERVICES                                         1\n",
      "NARCOTICS - FOUND                                         1\n",
      "Name: Final Call Type, Length: 193, dtype: int64 \n",
      "\n",
      "Call Type \n",
      " 911                              17857\n",
      "-                                12743\n",
      "ONVIEW                            7445\n",
      "TELEPHONE OTHER, NOT 911          2828\n",
      "ALARM CALL (NOT POLICE ALARM)      226\n",
      "PROACTIVE (OFFICER INITIATED)        2\n",
      "TEXT MESSAGE                         2\n",
      "SCHEDULED EVENT (RECURRING)          1\n",
      "Name: Call Type, dtype: int64 \n",
      "\n",
      "Officer Squad \n",
      " TRAINING - FIELD TRAINING SQUAD                   4310\n",
      "WEST PCT 1ST W - DAVID/MARY                       1273\n",
      "NORTH PCT 2ND WATCH - NORTH BEATS                  879\n",
      "WEST PCT 2ND W - D/M RELIEF                        874\n",
      "SOUTHWEST PCT 2ND W - FRANK                        838\n",
      "                                                  ... \n",
      "NAVIGATION TEAM - SQUAD B                            1\n",
      "TRAINING - LEARNING MANAGEMENT SYSTEM                1\n",
      "COMM - INTERNET AND TELEPHONE REPORTING (ITRU)       1\n",
      "RECORDS - DAY SHIFT                                  1\n",
      "CANINE - DAY SQUAD                                   1\n",
      "Name: Officer Squad, Length: 158, dtype: int64 \n",
      "\n",
      "Arrest Flag \n",
      " N    39355\n",
      "Y     1749\n",
      "Name: Arrest Flag, dtype: int64 \n",
      "\n",
      "Frisk Flag \n",
      " N    31577\n",
      "Y     9049\n",
      "-      478\n",
      "Name: Frisk Flag, dtype: int64 \n",
      "\n",
      "Precinct \n",
      " -            9485\n",
      "North        9166\n",
      "West         8937\n",
      "East         5515\n",
      "South        4893\n",
      "Southwest    2320\n",
      "SouthWest     558\n",
      "Unknown       200\n",
      "OOJ            18\n",
      "FK ERROR       12\n",
      "Name: Precinct, dtype: int64 \n",
      "\n",
      "Sector \n",
      " -         9664\n",
      "E         2337\n",
      "M         2270\n",
      "N         2191\n",
      "K         1762\n",
      "B         1658\n",
      "L         1639\n",
      "D         1512\n",
      "R         1455\n",
      "F         1378\n",
      "S         1348\n",
      "U         1302\n",
      "O         1161\n",
      "J         1119\n",
      "G         1087\n",
      "C         1037\n",
      "Q          967\n",
      "K          950\n",
      "W          941\n",
      "E          596\n",
      "M          569\n",
      "D          532\n",
      "N          377\n",
      "Q          375\n",
      "O          344\n",
      "F          337\n",
      "R          302\n",
      "S          282\n",
      "G          256\n",
      "B          236\n",
      "J          231\n",
      "U          223\n",
      "W          222\n",
      "C          202\n",
      "L          189\n",
      "99          53\n",
      "Name: Sector, dtype: int64 \n",
      "\n",
      "Beat \n",
      " -         9630\n",
      "N3        1175\n",
      "E2        1092\n",
      "M2         852\n",
      "M3         792\n",
      "          ... \n",
      "U3          45\n",
      "N1          42\n",
      "OOJ         17\n",
      "99          15\n",
      "S            2\n",
      "Name: Beat, Length: 107, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col, '\\n', df[col].value_counts(), '\\n')\n",
    "    \n",
    "# Most of the Stop resolutions do not result in resist - they result in field contact, or an offense report\n",
    "# We will combine those Arrested 9957  with those forward for Prosecution (728)\n",
    "# under the assumption that the police department and prosecutors are aware of the legal proof needed for arrest, and that the \n",
    "# case will likely result in arrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Findings from value_counts() and Next Steps:\n",
    "\n",
    "1. The \"-\" is used as a substitute for unknown, in many cases.  Perhaps it would be good to build a function to impute \"unknown\" for the \"-\" for multiple features\n",
    "2. Race and gender need re-mapping\n",
    "3. Call Types, Weapons need re-binning\n",
    "4. Officer Squad text can be split and provide the precinct, and the watch.\n",
    "\n",
    "**Next steps:**\n",
    "- [x] Investigation of the Stop Resolution, to determine whether the target should be \"Stop Resolution - Arrests\" or \"Arrest Flag\", and whether \"Frisk Flag\" is useful for predicting arrests.\n",
    "\n",
    "- [x] Decide whether time and location information can be extracted from the \"Officer Squad\" column instead of the columns for time, Precinct, Sector and Beats\n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Age Group</th>\n",
       "      <th>Stop Resolution</th>\n",
       "      <th>Weapon Type</th>\n",
       "      <th>Officer YOB</th>\n",
       "      <th>Officer Gender</th>\n",
       "      <th>Officer Race</th>\n",
       "      <th>Subject Perceived Race</th>\n",
       "      <th>Subject Perceived Gender</th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>Reported Time</th>\n",
       "      <th>Initial Call Type</th>\n",
       "      <th>Final Call Type</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Officer Squad</th>\n",
       "      <th>Arrest Flag</th>\n",
       "      <th>Frisk Flag</th>\n",
       "      <th>Precinct</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Beat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1984</td>\n",
       "      <td>M</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-10-16T00:00:00</td>\n",
       "      <td>11:32:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SOUTH PCT 1ST W - ROBERT</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>South</td>\n",
       "      <td>O</td>\n",
       "      <td>O2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32174</th>\n",
       "      <td>36 - 45</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1988</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Multi-Racial</td>\n",
       "      <td>Male</td>\n",
       "      <td>2019-04-13T00:00:00</td>\n",
       "      <td>11:35:00</td>\n",
       "      <td>THREATS - DV - NO ASSAULT</td>\n",
       "      <td>--ASSAULTS - HARASSMENT, THREATS</td>\n",
       "      <td>911</td>\n",
       "      <td>SOUTH PCT 1ST W - SAM</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>South</td>\n",
       "      <td>S</td>\n",
       "      <td>S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32172</th>\n",
       "      <td>36 - 45</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1991</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-04-09T00:00:00</td>\n",
       "      <td>01:13:00</td>\n",
       "      <td>ASLT - IP/JO - WITH OR W/O WPNS (NO SHOOTINGS)</td>\n",
       "      <td>--ASSAULTS, OTHER</td>\n",
       "      <td>911</td>\n",
       "      <td>WEST PCT 2ND W - KING</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>West</td>\n",
       "      <td>K</td>\n",
       "      <td>K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7804</th>\n",
       "      <td>18 - 25</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1990</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>2017-08-15T00:00:00</td>\n",
       "      <td>20:36:00</td>\n",
       "      <td>TRAFFIC STOP - OFFICER INITIATED ONVIEW</td>\n",
       "      <td>--TRAFFIC - REFUSE TO STOP (PURSUIT)</td>\n",
       "      <td>ONVIEW</td>\n",
       "      <td>WEST PCT 2ND W - D/M RELIEF</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>West</td>\n",
       "      <td>D</td>\n",
       "      <td>D2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32171</th>\n",
       "      <td>36 - 45</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1986</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2019-04-08T00:00:00</td>\n",
       "      <td>22:03:00</td>\n",
       "      <td>BURG - COMM BURGLARY (INCLUDES SCHOOLS)</td>\n",
       "      <td>--ROBBERY - STRONG ARM</td>\n",
       "      <td>911</td>\n",
       "      <td>WEST PCT 3RD W - QUEEN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>West</td>\n",
       "      <td>K</td>\n",
       "      <td>K1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23853</th>\n",
       "      <td>26 - 35</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>Firearm</td>\n",
       "      <td>1989</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Native Hawaiian or Other Pacific Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>2020-03-08T00:00:00</td>\n",
       "      <td>18:45:44</td>\n",
       "      <td>SUSPICIOUS STOP - OFFICER INITIATED ONVIEW</td>\n",
       "      <td>--WEAPON, PERSON WITH - GUN</td>\n",
       "      <td>ONVIEW</td>\n",
       "      <td>TRAINING - FIELD TRAINING SQUAD</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>East</td>\n",
       "      <td>C</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>18 - 25</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>2017-07-10T00:00:00</td>\n",
       "      <td>01:13:00</td>\n",
       "      <td>FIGHT - IP - PHYSICAL (NO WEAPONS)</td>\n",
       "      <td>--ASSAULTS, OTHER</td>\n",
       "      <td>ONVIEW</td>\n",
       "      <td>WEST PCT 3RD W - DAVID BEATS</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>West</td>\n",
       "      <td>M</td>\n",
       "      <td>M2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32277</th>\n",
       "      <td>36 - 45</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1990</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>2019-05-02T00:00:00</td>\n",
       "      <td>22:27:00</td>\n",
       "      <td>ASLT - IP/JO - WITH OR W/O WPNS (NO SHOOTINGS)</td>\n",
       "      <td>--ASSAULTS - HARASSMENT, THREATS</td>\n",
       "      <td>911</td>\n",
       "      <td>TRAINING - FIELD TRAINING SQUAD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>South</td>\n",
       "      <td>R</td>\n",
       "      <td>R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>18 - 25</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1971</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Male</td>\n",
       "      <td>2017-07-20T00:00:00</td>\n",
       "      <td>01:41:00</td>\n",
       "      <td>ASLT - WITH OR W/O WEAPONS (NO SHOOTINGS)</td>\n",
       "      <td>--ASSAULTS, OTHER</td>\n",
       "      <td>911</td>\n",
       "      <td>TRAINING - FIELD TRAINING SQUAD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>North</td>\n",
       "      <td>J</td>\n",
       "      <td>J1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>26 - 35</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>Lethal Cutting Instrument</td>\n",
       "      <td>1985</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>2016-04-01T00:00:00</td>\n",
       "      <td>16:40:00</td>\n",
       "      <td>SUSPICIOUS STOP - OFFICER INITIATED ONVIEW</td>\n",
       "      <td>--TRAFFIC - MOVING VIOLATION</td>\n",
       "      <td>ONVIEW</td>\n",
       "      <td>TRAINING - FIELD TRAINING SQUAD</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>F</td>\n",
       "      <td>F2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Subject Age Group Stop Resolution  ...  Sector    Beat\n",
       "0                     -          Arrest  ...  O       O2    \n",
       "32174           36 - 45          Arrest  ...  S       S1    \n",
       "32172           36 - 45          Arrest  ...  K       K3    \n",
       "7804            18 - 25          Arrest  ...  D       D2    \n",
       "32171           36 - 45          Arrest  ...  K       K1    \n",
       "...                 ...             ...  ...     ...     ...\n",
       "23853           26 - 35          Arrest  ...       C      C1\n",
       "7719            18 - 25          Arrest  ...  M       M2    \n",
       "32277           36 - 45          Arrest  ...  R       R2    \n",
       "7722            18 - 25          Arrest  ...  J       J1    \n",
       "15056           26 - 35          Arrest  ...  F       F2    \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Viewing the data to get a sense of which Stop Resolutions are correlated to the \"Arrest Flag\"\n",
    "df.sort_values(by=['Stop Resolution'], ascending=True).head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8210, 19)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out what are the differences between a Stop Resolution of \"Arrest\" and the \"Arrest Flag\" \n",
    "df.loc[(df['Stop Resolution']=='Arrest') & (df['Arrest Flag']==\"N\")].shape\n",
    "\n",
    "# This is the number of cases where the final stop resolution as reported by the officer, was \"Arrest\" and the\n",
    "# Arrest Flag was N.  This indicates that many arrests are finalized after the actual Terry Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 19)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['Stop Resolution']!='Arrest') & (df['Arrest Flag']==\"Y\")].shape\n",
    "\n",
    "# Number of times an arrest was not made,  but the arrest flag was yes (an arrest was made during the Terry Stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1747, 19)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['Stop Resolution']=='Arrest') & (df['Arrest Flag']==\"Y\")].shape\n",
    "\n",
    "# These are the number of arrests DURING the Terry stop,  that had a final resolution of arrest\n",
    "\n",
    "# Conclusion:  Few Terry stops can result in arrest during the stop. Followup investigation is needed.\n",
    "# Use the Stop Resolution of Arrest to capture all the arrests made arising from a Terry stop\n",
    "# The total number of arrests as reported by the officers is 8210 + 1747 or ~ 25% of the total # of Terry stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3235, 19)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to see whether the Frisk Flag has usefulness\n",
    "df.loc[(df['Stop Resolution']=='Arrest') & (df['Frisk Flag']==\"Y\")].shape\n",
    "\n",
    "# Out of 10,000 arrests (and ~ 9000 Frisks), the number of arrest, that were frisked was ~\n",
    "# May still have value as a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5888, 19)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CheckType whether 'Call Type' has usefulness\n",
    "df.loc[(df['Stop Resolution']=='Arrest') & (df['Call Type']==\"911\")].shape\n",
    "\n",
    "# Out of ~10,000 arrests roughly 50% came through 911.  Doesn't appear to be particularly useful for predicting arrests\n",
    "# Drop the 'Call Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Age Group</th>\n",
       "      <th>Stop Resolution</th>\n",
       "      <th>Weapon Type</th>\n",
       "      <th>Officer YOB</th>\n",
       "      <th>Officer Gender</th>\n",
       "      <th>Officer Race</th>\n",
       "      <th>Subject Perceived Race</th>\n",
       "      <th>Subject Perceived Gender</th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>Reported Time</th>\n",
       "      <th>Initial Call Type</th>\n",
       "      <th>Final Call Type</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Officer Squad</th>\n",
       "      <th>Arrest Flag</th>\n",
       "      <th>Frisk Flag</th>\n",
       "      <th>Precinct</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Beat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1984</td>\n",
       "      <td>M</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>2015-10-16T00:00:00</td>\n",
       "      <td>11:32:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SOUTH PCT 1ST W - ROBERT</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>South</td>\n",
       "      <td>O</td>\n",
       "      <td>O2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1963</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2015-04-01T00:00:00</td>\n",
       "      <td>04:55:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1985</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2015-05-25T00:00:00</td>\n",
       "      <td>01:06:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>WEST PCT 3RD W - MARY</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>19:27:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>19:32:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Age Group Stop Resolution Weapon Type  ...  Precinct  Sector    Beat\n",
       "0                 -          Arrest        None  ...     South  O       O2    \n",
       "1                 -   Field Contact        None  ...         -       -       -\n",
       "2                 -   Field Contact        None  ...         -       -       -\n",
       "3                 -   Field Contact        None  ...         -       -       -\n",
       "4                 -   Field Contact        None  ...         -       -       -\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Scoping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which is better to use the \"Arrest Flag\" column or the \"Stop Resolution column as the target?: <br><br>\n",
    "\n",
    "* Arrest Flag is a'1' only when there was an actual arrest during the Terry Stop.  Which may not be easy to do, resulting in a lower number (1747) <br><br>\n",
    "\n",
    "* Stop Resolution records ~10,000 arrests, roughly 25% of the total dataset.  Since Stop Resolution is about officers recording the resolution of the Terry Stop, and with a likely performance target for officers,  they are likely to record this more accurately. <br><br>\n",
    "\n",
    "* A quick check of \"Frisk Flag\" which is an indicator of those Terry stops where a Frisk was performed, does not seem well correlated with arrests.  Recomend to drop \"Frisk Flag\" <br><br>\n",
    "\n",
    "#### Conclusion: Use \"Stop Resolution\" Arrests as the target\n",
    "\n",
    "  - [x] Create a new column called \"Arrests\" which encodes Stop Resolution Arrests as a \"1\" and all others \"0\".  \n",
    "  - [x] Drop the \"Arrest Flag\" column\n",
    "  - [x] Drop the \"Frisk Flag\" column <br><br>\n",
    "    \n",
    "2. Location data, there are a number of columns which relate to location such as \"Precincts\", \"Officer Squad\", \"Sector\", \"Beat\", but are indirect measures of the actual location of the Terry Stop. Inspection of the \"Officer Squad\" text shows the Location assignment of the officer making the report. In ~10% of cases, Terry stops were performed by field training units or other units which are not captured by precinct (hence roughly 25% of the precincps are unknown). The training unit information is captured in the \"Officer Squad\" column.  <br><br>\n",
    "\n",
    "3. For time data there is a \"Reported Time\" -- which is the time when the officer report was submitted, and according to the documentation could be delayed up to 10 hours, rather than the time of the actual Terry stop. <br><br> \n",
    "\n",
    "    However, inspection of the text in \"Officer Squad\" shows that the reporting officer's watch is recorded. In the Seattle police squad there are 3 watches to cover each 24 hour period. Watch 1 (03:00 - 11:00), Watch 2 (11:00 - 19:00), and Watch 3 (19:00 - 03:00).  Since officer performance is rated based on number of cases and crimes prevented or apprehended, likely the \"Officer Squad\" data which comes from the report is likely to be the most reliable in terms of time.\n",
    "    \n",
    "#### Conclusion: Use \"Officer Squad\" text data for time and location\n",
    "\n",
    "- [x] Parse the \"Officer Squad\" data to capture the location and time based on officer assignments, creating columns for location and watch. <br><br>\n",
    "\n",
    "- [x] Drop the \"Reported Time\", \"Precincts\", \"Sector\", and \"Beat\" columns <br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Arrest Flag', 'Frisk Flag', 'Reported Time', 'Precinct', 'Sector', 'Beat'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2285"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-Check for duplicates\n",
    "#duplicates = seattle_df[seattle_df.duplicated(subset =['id'], keep = False)]\n",
    "#duplicates.sort_values(by=['id']).head()\n",
    "duplicates = df[df.duplicated(keep = False)]\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding from duplicated():\n",
    "- If you look at the beginning of the analysis, I checked for duplications with the entire dataset (before removing columns of data, such as \"ID\"),  there were no duplicates. But after dropping the ID,  there are 118 rows in duplication, 59 pairs. <br><br>\n",
    "\n",
    "- Because the date and time are not exact (the documentation says sometimes the date could have been entered 24 hours later, or the time could be off by 10 hours, so that actually unique Terry stops could have the same data (when the ID columns are removed).<br><br>\n",
    "\n",
    "- There are a few that are arrests.  Still open to decide whether to remove the duplicated data or not.  <br><br>\n",
    "\n",
    "- What is curious is that the index number is not always consecutive between different pairs of duplicates.  This suggests that perhaps the data was input twice -- maybe due to some computer or internet glitches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Data Transformation\n",
    "\n",
    "   * Officer data: YOB, race, gender\n",
    "   * Subject data- Age Group, race, gender\n",
    "   * Stop Resolution (target column)\n",
    "   * Weapons\n",
    "   * Type of potential crime: Call type Initial and Final \n",
    "   * Date to day of week\n",
    "   * Location and time: from Officer Squad\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Transform Gender Using Dictionary Mapping .map()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-mapping gender categories.  we will be doing 1 hot encoding, so leave in the text\n",
    "\n",
    "# officer_gender\n",
    "officer_gender = {'M': 0, 'F': 1, 'N': 2}\n",
    "df['Officer Gender'] = df['Officer Gender'].map(officer_gender)\n",
    "\n",
    "# subject perceived gender\n",
    "subject_gender = {'Male': 0, 'Female':1, 'Unknown':2,  '-':2, \n",
    "                 'Unable to Determine':2, 'Gender Diverse (gender non-conforming and/or transgender)':2}\n",
    "df['Subject Perceived Gender'] = df['Subject Perceived Gender'].map(subject_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36504\n",
       "1     4593\n",
       "2        7\n",
       "Name: Officer Gender, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the mapping\n",
    "df.loc[(df['Officer Gender']== 'Male')].shape, df.loc[(df['Subject Perceived Gender']== 'Male')].shape\n",
    "df['Officer Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    32049\n",
       "1     8468\n",
       "2      587\n",
       "Name: Subject Perceived Gender, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject Perceived Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mapping\n",
    "df['Officer Gender'].isna().sum(), df['Subject Perceived Gender'].isna().sum()  #NAs are not found "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### B. Transform Age Using Dictionary Mapping .map() and binning (.cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We will forgo remapping because we will be doing one-hot encoding\n",
    "subject_age = {'1 - 17':'1-17', '18 - 25':'18-25', '26 - 35':'26-35', '36 - 45':'36-45', '46 - 55':'46-55', \n",
    "               '56 and Above':'56+', '-':'Unknown'}\n",
    "df['Subject Age Group'] = df['Subject Age Group'].map(subject_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject Age Group'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35      13615\n",
       "36-45       8547\n",
       "18-25       8509\n",
       "46-55       5274\n",
       "56+         1996\n",
       "1-17        1876\n",
       "Unknown     1287\n",
       "Name: Subject Age Group, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject Age Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2015\n",
       "1        2015\n",
       "2        2015\n",
       "3        2015\n",
       "4        2015\n",
       "         ... \n",
       "41099    2020\n",
       "41100    2020\n",
       "41101    2020\n",
       "41102    2020\n",
       "41103    2020\n",
       "Name: Reported Year, Length: 41104, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the Officers Age, and bin into same bins as the subject age\n",
    "df['Reported Year']=pd.to_datetime(df['Reported Date']).dt.year\n",
    "df['Reported Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31     2842\n",
       "30     2592\n",
       "32     2515\n",
       "33     2443\n",
       "29     2246\n",
       "34     2206\n",
       "28     2140\n",
       "26     1923\n",
       "27     1869\n",
       "35     1723\n",
       "25     1544\n",
       "24     1425\n",
       "36     1226\n",
       "37     1184\n",
       "38     1096\n",
       "39      970\n",
       "40      945\n",
       "42      806\n",
       "41      753\n",
       "23      730\n",
       "45      698\n",
       "46      679\n",
       "44      664\n",
       "48      618\n",
       "43      593\n",
       "47      582\n",
       "49      543\n",
       "50      533\n",
       "54      436\n",
       "51      399\n",
       "53      377\n",
       "52      310\n",
       "55      308\n",
       "56      242\n",
       "22      241\n",
       "57      203\n",
       "58      177\n",
       "59       88\n",
       "60       69\n",
       "61       39\n",
       "63       32\n",
       "21       19\n",
       "62       19\n",
       "65       16\n",
       "64       13\n",
       "67       12\n",
       "68        4\n",
       "118       3\n",
       "116       2\n",
       "119       2\n",
       "70        1\n",
       "69        1\n",
       "117       1\n",
       "66        1\n",
       "115       1\n",
       "Name: Officer Age, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Officer Age'] = df['Reported Year'] - df['Officer YOB']\n",
    "df['Officer Age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26-35      22499\n",
       "36-45       8935\n",
       "46-55       4785\n",
       "18-25       3959\n",
       "56+          917\n",
       "Unknown        9\n",
       "1-17           0\n",
       "Name: Officer Age, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Officer Age'] =pd.cut(x=df['Officer Age'], bins=[1,18,25,35,45,55,70,120], labels = ['1-17', \n",
    "                          '18-25','26-35','36-45', '46-55', '56+', 'Unknown'])\n",
    "df['Officer Age'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Age Group</th>\n",
       "      <th>Stop Resolution</th>\n",
       "      <th>Weapon Type</th>\n",
       "      <th>Officer YOB</th>\n",
       "      <th>Officer Gender</th>\n",
       "      <th>Officer Race</th>\n",
       "      <th>Subject Perceived Race</th>\n",
       "      <th>Subject Perceived Gender</th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>Initial Call Type</th>\n",
       "      <th>Final Call Type</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Officer Squad</th>\n",
       "      <th>Reported Year</th>\n",
       "      <th>Officer Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Arrest</td>\n",
       "      <td>None</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-16T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SOUTH PCT 1ST W - ROBERT</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-04-01T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2015</td>\n",
       "      <td>46-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-25T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>WEST PCT 3RD W - MARY</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>Field Contact</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Age Group Stop Resolution  ... Reported Year  Officer Age\n",
       "0           Unknown          Arrest  ...          2015        26-35\n",
       "1           Unknown   Field Contact  ...          2015        46-55\n",
       "2           Unknown   Field Contact  ...          2015        26-35\n",
       "3           Unknown   Field Contact  ...          2015        36-45\n",
       "4           Unknown   Field Contact  ...          2015        36-45\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### C. Transform Gender using Dictionary Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White                                        20192\n",
       "Black or African American                    12243\n",
       "Unknown                                       2073\n",
       "Hispanic                                      1684\n",
       "-                                             1422\n",
       "Asian                                         1278\n",
       "American Indian or Alaska Native              1224\n",
       "Multi-Racial                                   809\n",
       "Other                                          152\n",
       "Native Hawaiian or Other Pacific Islander       27\n",
       "Name: Subject Perceived Race, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many arrested had unknown race (or - or other)\n",
    "\n",
    "df.loc[(df['Stop Resolution']=='Arrest') & (df['Subject Perceived Race']== \"Unknown\")].shape\n",
    "#df.loc[(df['Stop Resolution']=='Arrest') & (df['Subject Perceived Race']== \"-\")].shape\n",
    "#df.loc[(df['Stop Resolution']=='Arrest') & (df['Subject Perceived Race']== \"Other\")].shape\n",
    "df['Subject Perceived Race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "race_map = {'White': 'White', 'Black or African American':'African American', 'Hispanic':'Hispanic',\n",
    "            'Hispanic or Latino':'Hispanic', 'Two or More Races':'Multi-Racial','Multi-Racial':'Multi-Racial',\n",
    "           'American Indian or Alaska Native':'Native', 'American Indian/Alaska Native':'Native',  \n",
    "            'Native Hawaiian or Other Pacific Islander':'Native', 'Nat Hawaiian/Oth Pac Islander':'Native',\n",
    "           '-':'Unknown', 'Other':'Unknown', 'Not Specified':'Unknown','Unknown':'Unknown',\n",
    "           'Asian': 'Asian',}\n",
    "\n",
    "df['Subject Perceived Race'] = df['Subject Perceived Race'].map(race_map)\n",
    "df['Officer Race'] = df['Officer Race'].map(race_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White               31805\n",
       "Hispanic             2255\n",
       "Multi-Racial         2158\n",
       "African American     1674\n",
       "Asian                1563\n",
       "Unknown               921\n",
       "Native                728\n",
       "Name: Officer Race, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Officer Race'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White               20192\n",
       "African American    12243\n",
       "Unknown              3647\n",
       "Hispanic             1684\n",
       "Asian                1278\n",
       "Native               1251\n",
       "Multi-Racial          809\n",
       "Name: Subject Perceived Race, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subject Perceived Race'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### D. Transform Stop Resolution Using Dictionary Mapping .map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Field Contact               16287\n",
       "Offense Report              13976\n",
       "Arrest                       9957\n",
       "Referred for Prosecution      728\n",
       "Citation / Infraction         156\n",
       "Name: Stop Resolution, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now address the Stop Resolution categories\n",
    "df['Stop Resolution'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    30419\n",
       "1    10685\n",
       "Name: Stop Resolution, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-map the Stop Resolution, to combine categories Arrest and Referred for Prosecution\n",
    "# Map Arrest and Referred for Prosecution to 1,  and all others 0\n",
    "stop_resolution = {'Field Contact': 0, 'Offense Report': 0, 'Arrest': 1,\n",
    "             'Referred for Prosecution': 1, 'Citation / Infraction': 0}\n",
    "\n",
    "df['Stop Resolution']=df['Stop Resolution'].map(stop_resolution)\n",
    "df['Stop Resolution'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Transform Weapon Type Using a Dictionary and .map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Age Group</th>\n",
       "      <th>Stop Resolution</th>\n",
       "      <th>Weapon Type</th>\n",
       "      <th>Officer YOB</th>\n",
       "      <th>Officer Gender</th>\n",
       "      <th>Officer Race</th>\n",
       "      <th>Subject Perceived Race</th>\n",
       "      <th>Subject Perceived Gender</th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>Initial Call Type</th>\n",
       "      <th>Final Call Type</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Officer Squad</th>\n",
       "      <th>Reported Year</th>\n",
       "      <th>Officer Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>African American</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-16T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SOUTH PCT 1ST W - ROBERT</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-04-01T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2015</td>\n",
       "      <td>46-55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-25T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>WEST PCT 3RD W - MARY</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09T00:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Age Group  Stop Resolution  ... Reported Year  Officer Age\n",
       "0           Unknown                1  ...          2015        26-35\n",
       "1           Unknown                0  ...          2015        46-55\n",
       "2           Unknown                0  ...          2015        26-35\n",
       "3           Unknown                0  ...          2015        36-45\n",
       "4           Unknown                0  ...          2015        36-45\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None                                 32565\n",
       "-                                     6213\n",
       "Lethal Cutting Instrument             1482\n",
       "Knife/Cutting/Stabbing Instrument      308\n",
       "Handgun                                262\n",
       "Firearm Other                          100\n",
       "Club, Blackjack, Brass Knuckles         49\n",
       "Blunt Object/Striking Implement         37\n",
       "Firearm                                 18\n",
       "Firearm (unk type)                      15\n",
       "Other Firearm                           13\n",
       "Mace/Pepper Spray                       12\n",
       "Club                                     9\n",
       "Rifle                                    5\n",
       "None/Not Applicable                      4\n",
       "Taser/Stun Gun                           4\n",
       "Shotgun                                  3\n",
       "Automatic Handgun                        2\n",
       "Brass Knuckles                           1\n",
       "Fire/Incendiary Device                   1\n",
       "Blackjack                                1\n",
       "Name: Weapon Type, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now re-map Weapon Type feature.  First check the categories of Weapons\n",
    "df['Weapon Type'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown         38782\n",
       "Lethal Blade     1790\n",
       "Firearm           418\n",
       "Blunt Force        97\n",
       "Spray              12\n",
       "Taser               4\n",
       "Incendiary          1\n",
       "Name: Weapon Type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weapon_type = {'None':'Unknown', 'None/Not Applicable':'Unknown', 'Fire/Incendiary Device':'Incendiary',\n",
    "              'Lethal Cutting Instrument':'Lethal Blade', 'Knife/Cutting/Stabbing Instrument':'Lethal Blade',\n",
    "              'Handgun':'Firearm', 'Firearm Other':'Firearm','Firearm':'Firearm', 'Firearm (unk type)':'Firearm',\n",
    "              'Other Firearm':'Firearm', 'Rifle':'Firearm', 'Shotgun':'Firearm', 'Automatic Handgun':'Firearm',\n",
    "              'Club, Blackjack, Brass Knuckles':'Blunt Force', 'Club':'Blunt Force', \n",
    "              'Brass Knuckles':'Blunt Force', 'Blackjack':'Blunt Force', 'Incendiary':'Incendiary',\n",
    "              'Blunt Object/Striking Implement':'Blunt Force', '-':'Unknown', 'Unknown': 'Unknown',\n",
    "              'Taser/Stun Gun':'Taser', 'Mace/Pepper Spray':'Spray', 'Blunt Force':'Blunt Force',\n",
    "              \"Taser\":\"Taser\", \"Spray\":'Spray', 'Lethal Blade':'Lethal Blade' }\n",
    "\n",
    "df['Weapon Type']=df['Weapon Type'].map(weapon_type)\n",
    "df['Weapon Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Transform the Date using to_datetime, .weekday, and .day\n",
    "\n",
    "* Calculate the reported date of the week\n",
    "    - [x] Day of the week: 0 = Monday, 6 = Sunday\n",
    "    <br><br>\n",
    "    \n",
    "* Calculate the first, mid and last weeks of the month because perhaps more crimes / arrests are made when the bills come due\n",
    "    - [x] Time of month: 1 = First week, 2 = 2nd and 3rd weeks,  4 = last week of the month\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2015-10-16T00:00:00\n",
       "1    2015-04-01T00:00:00\n",
       "2    2015-05-25T00:00:00\n",
       "3    2015-06-09T00:00:00\n",
       "4    2015-06-09T00:00:00\n",
       "Name: Reported Date, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reported Date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Reported date into a day of the week,  or the time of month \n",
    "# Day of the week: 0 = Monday, 6 = Sunday\n",
    "# Time of month: 1 = First week, 2 = 2nd and 3rd weeks,  4 = last week of the month\n",
    "\n",
    "df['Reported Date']=pd.to_datetime(df['Reported Date'])  # Processed earlier for Officer YOB calculation\n",
    "df['Weekday']=df['Reported Date'].dt.weekday\n",
    "\n",
    "df['Time of Month'] = df['Reported Date'].dt.day\n",
    "\n",
    "month_map = {1:1, 2:1,3:1,4:1, 5:1, 6:1, 7:1,8:2, 9:2, 10:2, 11:2, 12:2, 13:2, 14:2, 15:2, \n",
    "                     16:2, 17:2, 18:2, 19:2, 20:2, 21:2, 22:2, 23:3, 24:3, 25:3, 26:3, 27:3, 28:3, 29:3, 30:3, 31:3}\n",
    "\n",
    "df['Time of Month'] = df['Time of Month'].map(month_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject Age Group           0\n",
       "Stop Resolution             0\n",
       "Weapon Type                 0\n",
       "Officer YOB                 0\n",
       "Officer Gender              0\n",
       "Officer Race                0\n",
       "Subject Perceived Race      0\n",
       "Subject Perceived Gender    0\n",
       "Reported Date               0\n",
       "Initial Call Type           0\n",
       "Final Call Type             0\n",
       "Call Type                   0\n",
       "Officer Squad               0\n",
       "Reported Year               0\n",
       "Officer Age                 0\n",
       "Weekday                     0\n",
       "Time of Month               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject Age Group</th>\n",
       "      <th>Stop Resolution</th>\n",
       "      <th>Weapon Type</th>\n",
       "      <th>Officer YOB</th>\n",
       "      <th>Officer Gender</th>\n",
       "      <th>Officer Race</th>\n",
       "      <th>Subject Perceived Race</th>\n",
       "      <th>Subject Perceived Gender</th>\n",
       "      <th>Reported Date</th>\n",
       "      <th>Initial Call Type</th>\n",
       "      <th>Final Call Type</th>\n",
       "      <th>Call Type</th>\n",
       "      <th>Officer Squad</th>\n",
       "      <th>Reported Year</th>\n",
       "      <th>Officer Age</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Time of Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1984</td>\n",
       "      <td>0</td>\n",
       "      <td>African American</td>\n",
       "      <td>Asian</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-16</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>SOUTH PCT 1ST W - ROBERT</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2015</td>\n",
       "      <td>46-55</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-05-25</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>WEST PCT 3RD W - MARY</td>\n",
       "      <td>2015</td>\n",
       "      <td>26-35</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NORTH PCT 2ND W - NORA</td>\n",
       "      <td>2015</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject Age Group  Stop Resolution  ... Weekday  Time of Month\n",
       "0           Unknown                1  ...       4              2\n",
       "1           Unknown                0  ...       2              1\n",
       "2           Unknown                0  ...       0              3\n",
       "3           Unknown                0  ...       1              2\n",
       "4           Unknown                0  ...       1              2\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Use Officer Squad data to create the location information (Precinct or Officer Team) and the time of day of the arrest (Officer Watch)\n",
    "\n",
    "* Use Pandas Regex .str.extract to get the name of the precinct and the Watch if available\n",
    "\n",
    "* Analyse if some precincts / units never make arrests \n",
    "\n",
    "* The Officer Squad text data is likely more reliable estimate assuming use the information provided is the squad name / location, and the watch that handled the reports, not a specific person schedule or squad. <br><br>\n",
    "* With the Reported Date and Time, since the reports can come 1 day, or 10 hours later, the recorded time is not the actual Terry stop time. <br><br>\n",
    "* Features created from Officer Squad: <br><br>\n",
    "    - [x] Precinct or Squad name following the Terry stop\n",
    "    - [x] Watch: <br>\n",
    "        0 = Unknown, if the watch is not normally recorded<br>\n",
    "        1 = Watch 1 03:00 - 11:00<br>\n",
    "        2 = Watch 2 11:00 - 19:00<br>\n",
    "        3 = Watch 3 19:00 - 03:00<br>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Python Regex commands to clean up the Call Types and Officer Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Officer Squad'].value_counts()\n",
    "\n",
    "df['Precinct'] = df['Officer Squad'].str.extract(r'(\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      14196\n",
       "3      11806\n",
       "1       8423\n",
       "NaN     6676\n",
       "4          3\n",
       "Name: Watch, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Watch'] = df['Officer Squad'].str.extract(pat = '([\\d])')\n",
    "df['Watch'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2nd Watch      14196\n",
       "3rd Watch      11806\n",
       "First Watch     8423\n",
       "Unknown         6679\n",
       "Name: Watch, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watch_map = { \"1\" : \"First Watch\", \"2\": \"2nd Watch\", \"3\":\"3rd Watch\", np.nan:'Unknown', \"4\":'Unknown'}\n",
    "\n",
    "df['Watch'] = df['Watch'].map(watch_map)\n",
    "df['Watch'].value_counts(dropna=False)\n",
    "\n",
    "\n",
    "# Some Officer Quads do not recorde the Watch number \n",
    "# Don't leave the NaNs in the Watch column, fill with 0\n",
    "# Watch definition: 0 = Unknown, 1 = 1st Watch, 2 = 2nd Watch, 3 = 3rd Watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the Precincts are not typically making arrests, by comparing the number of arrests (Stop Resolution = Arrest)\n",
    "# to the total number of Terry stops. \n",
    "\n",
    "\n",
    "arrest_df = df.loc[df['Stop Resolution'] == 1]  # Dataframe only for those Terry stops that resulted in arrests\n",
    "\n",
    "arrest_df['Precinct'].value_counts(), df['Precinct'].value_counts()  # compare the value_counts for both dataframes\n",
    "\n",
    "# Subsetting to only the Stop Resolution of arrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate the # of precincts that have arrests by dividing the arrest_df to the total number of terry stops\n",
    "\n",
    "arrest_percentage = arrest_df['Precinct'].value_counts() / df['Precinct'].value_counts()\n",
    "print(f'The percentage of arrests based on terry stops, by squad \\n\\n',arrest_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrest_percentage.fillna(0, inplace=True)- Drop those precincts that don't typically make arrests (or havent made an arrest \n",
    "# to date)\n",
    "\n",
    "display(f'The percentage of arrests based on terry stops, by squad',arrest_percentage *100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for mapping the squads which have successful arrest.  Those officer squads which have\n",
    "# reported Terry stops with no arrests will be dropped from the dataset\n",
    "successful_arrest_map=arrest_percentage.to_dict()\n",
    "# successful_arrest_map # Take a look at the dictionary\n",
    "\n",
    "df['Precinct Success']=df['Precinct'].map(successful_arrest_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 36 units / precincts which do not have any arrests since 2015\n",
    "# Likely these units are not expected to make arrests\n",
    "\n",
    "#df.to_csv('terry_stops_cleanup3.csv') #save with all manipulations except for Call Types, without dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop out the units Terry stops which do not routinely make arrests\n",
    "df.dropna(inplace=True)  # Drop the squads with no arrests\n",
    "df.reset_index(inplace=True)  # Reset the Index\n",
    "df.drop(columns=['Call Type', 'Reported Date', 'Officer Squad'], inplace = True) # Drop Processed Columns\n",
    "#df.to_csv('terry_stops_cleanup4.csv') #Save after dropping squads with no arrests and columns and reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Transform Initial or Final Call Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_map = clean_call_types(df,'Final Call Type', 'Final Call Re-map')\n",
    "\n",
    "initial_map = clean_call_types(df, 'Initial Call Type', 'Initial Call Re-map')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if keys of the two dictionaries are the same\n",
    "diff = set(final_map) - set(initial_map)  # the keys in final_map and not in initial_map\n",
    "diff2 = set(initial_map) - set(final_map) # the keys that are in initial_map, and not in final_map\n",
    "\n",
    "diff, diff2\n",
    "# Expand the existing call map to include additional keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This call dictionary was built on the final calls,  not the initial calls text.  So add the initial calls and input values\n",
    "\n",
    "call_dictionary = {'unknown': 'unknown',\n",
    "             'suspicious': 'suspicious',\n",
    "             'assaults': 'assault',\n",
    "             'disturbance': 'disturbance',\n",
    "             'prowler': 'trespass',\n",
    "             'dv': 'domestic violence',\n",
    "             'warrant': 'warrant',\n",
    "             'theft': 'theft',\n",
    "             'narcotics': 'under influence',\n",
    "             'robbery': 'theft',\n",
    "             'burglary': 'theft',\n",
    "             'traffic': 'traffic',\n",
    "             'property': 'property damage',\n",
    "             'weapon': 'weapon',\n",
    "             'crisis': 'person in crisis',\n",
    "             'automobiles': 'auto',\n",
    "             'assist': 'assist others',\n",
    "             'sex': 'vice',\n",
    "             'mischief': 'mischief',\n",
    "             'arson': 'arson',\n",
    "             'fraud': 'fraud',\n",
    "             'vice': 'vice',\n",
    "             'drive': 'auto',\n",
    "             'misc': 'misdemeanor',\n",
    "             'premise': 'trespass',\n",
    "             'alarm': 'suspicious',\n",
    "             'intox': 'under influence',\n",
    "             'rape': 'rape',\n",
    "             'child': 'child',\n",
    "             'trespass': 'trespass',\n",
    "             'person': 'person in crisis',\n",
    "             'homicide': 'homicide',\n",
    "             'burg': 'theft',\n",
    "             'kidnap': 'kidnap',\n",
    "             'animal': 'animal',\n",
    "             'hazards': 'hazard',\n",
    "             'aslt': 'assault',\n",
    "             'casualty': 'homicide',\n",
    "             'fight': 'disturbance',\n",
    "             'shoplift': 'theft',\n",
    "             'auto': 'auto', \n",
    "             'haras': 'disturbance',\n",
    "             'purse': 'theft',\n",
    "             'weapn': 'weapon',\n",
    "             'fireworks': 'arson',\n",
    "             'follow': 'disturbance',\n",
    "             'dist': 'disturbance',\n",
    "             'haz': 'hazard',\n",
    "             'nuisance': 'mischief',\n",
    "             'threats': 'disturbance',\n",
    "             'liquor': 'under influence',\n",
    "             'mvc': 'auto',\n",
    "             'shots': 'weapon',\n",
    "             'harbor': 'auto',\n",
    "             'down': 'homicide',\n",
    "             'service': 'unknown',\n",
    "             'hospital': 'unknown',\n",
    "             'bomb': 'arson',\n",
    "             'undercover': 'under influence',\n",
    "             'burn': 'arson',\n",
    "             'lewd': 'vice',\n",
    "             'dui': 'under influence',\n",
    "             'crowd': 'unknown',\n",
    "             'order': 'assist',\n",
    "             'escape': 'assist',\n",
    "             'commercial': 'trespass',\n",
    "             'noise': 'disturbance',\n",
    "             'narcotics': 'under influence',\n",
    "             'awol': 'kidnap',\n",
    "              'bias': 'unknown',\n",
    "              'carjacking': 'kidnap',\n",
    "              'demonstrations':'disturbance',\n",
    "              'directed':'unknown',\n",
    "              'doa':'assist',\n",
    "              'explosion':'arson',\n",
    "              'foot': 'trespass',\n",
    "              'found':'unknown',\n",
    "              'gambling': 'vice',\n",
    "              'help':'assist',\n",
    "              'illegal':'assist',\n",
    "              'injured':'assist',\n",
    "              'juvenile':'child',\n",
    "              'littering': 'nuisance',\n",
    "              'missing': 'kidnap',\n",
    "              'off':'suspicious',\n",
    "              'open':'unknown',\n",
    "              'overdose':'under influence',\n",
    "              'panhandling':'disturbance',\n",
    "              'parking':'disturbance',\n",
    "              'parks':'disturbance',\n",
    "              'peace':'disturbance',\n",
    "              'pedestrian':'disturbance',\n",
    "              'phone':'disturbance',\n",
    "              'request':'assist',\n",
    "              'sfd':'assist',\n",
    "              'sick':'assist',\n",
    "              'sleeper':'disturbance',\n",
    "              'suicide':'assist'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Final Call Re-map'] = df['Final Call Re-map'].map(call_dictionary)\n",
    "df['Final Call Re-map'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Initial Call Re-map'] = df['Initial Call Re-map'].map(call_dictionary)\n",
    "df['Initial Call Re-map'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all NaNs\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.to_csv('terry_stops_cleanup4.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['Initial Call Type', 'Final Call Type', 'Precinct Success', 'Officer YOB',\n",
    "                  'Reported Year', 'level_0', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = df.copy()\n",
    "\n",
    "df.to_csv('terry_stops_categorical.csv')\n",
    "cat_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Precinct'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vanilla Model\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model: 1-hot encoded, XGBoost with Initial Call data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_call_df_to_split = df.drop(columns = ['Final Call Re-map','Stop Resolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = initial_call_df_to_split.columns\n",
    "\n",
    "target_col = df['Stop Resolution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.get_dummies(initial_call_df_to_split, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the correlations information\n",
    "plt.savefig(\"Correlation.png\")\n",
    "plt.savefig(\"Correlation 2.png\", transparent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cat_cols = df.columns\n",
    "for header in cat_cols:\n",
    "    df[header] = df[header].astype('category').cat.codes\n",
    "\n",
    "sns.axes_style(\"white\")\n",
    "\n",
    "pearson = df.corr(method = 'pearson')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,12)})\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(pearson)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(data=pearson, mask=mask, cmap=\"YlGnBu\", \n",
    "                 annot=True, square=True, cbar_kws={'shrink': 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Correlation Matrix for Multi-Collinear features\n",
    "\n",
    "* **Conclusions**\n",
    "\n",
    "    - [x] Well, this is categorical data, and maybe you aren't going to see strong correlations ?\n",
    "    - [x] If you leave both Initial Call Type and Final Call type in the dataframe,  of course they are correlated, so you can't keep both in the model. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = df_to_split['Stop Resolution']\n",
    "X = df_to_split.drop('Stop Resolution',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = pd.get_dummies(df_to_split, drop_first=True)\n",
    "\n",
    "y = df['Stop Resolution']\n",
    "y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Train test split\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#,stratify=y)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rf = XGBRFClassifier()\n",
    "xgb_rf.fit(X_train, y_train)\n",
    "print('Training Accuracy score: ' ,round(xgb_rf.score(X_train,y_train),2))\n",
    "print('Test Accuracy score: ',round(xgb_rf.score(X_test,y_test),2))\n",
    "y_hat_test = xgb_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, xgb_rf, expt_name='Test A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.DataFrame()\n",
    "\n",
    "metrics_summary = metrics_df.copy() # Initialize the Metric Summary\n",
    "#metrics_summery = pd.merge(metrics_summary, metrics_df, how = 'left', on = metrics_summary['key'])\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.DataFrame()\n",
    "comparison = comps.copy() # Initialize the comparison table\n",
    "comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "source": [
    "## 5. Vanilla Model Results & Experimental Plan\n",
    "\n",
    "* Results: \n",
    "    - [x] \"Initial Call Type\" is the most important feature, with \"Weapon\" and \"Officer Age\" as the 2nd and 3rd most important features, respectively. <br>\n",
    "    - [x] Training accuracy of 0.76, and testing accuracy of 0.74 <br>\n",
    "    - [x] However, the Confusion Matrix shows the main reason is that the \"Non-arrests\" are better classified than the arrests.  For arrests, the true negatives were well predicted (96%), and the true positives were poorly predicted (14%), while false positives were 86%.\n",
    "    - [x] This seems to make sense given the class imbalance (only 25% of the data were arrests) <br>\n",
    "    - [x] The AOC was well above random chance  but still low (< 0.8) <br> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B - XGB + Final Call Type\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = backup_df.copy()\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change input to drop Initial Call Type and keep Final Call Type\n",
    "final_call_df_to_split = df.drop(columns = ['Initial Call Re-map','Stop Resolution'])\n",
    "#category_cols = df_to_split.columns\n",
    "#target_col = ['Stop Resolution']\n",
    "\n",
    "X = pd.get_dummies(final_call_df_to_split,)# drop_first=True)\n",
    "# Convert catogories to cat.codes\n",
    "\n",
    "#for header in category_cols:#    df_to_split[header] = df[header].astype('category').cat.codes\n",
    "#df_to_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = df['Stop Resolution']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#,stratify=y)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n",
    "\n",
    "xgb_rf = XGBRFClassifier()\n",
    "xgb_rf.fit(X_train, y_train)\n",
    "print('Training Accuracy score: ' ,round(xgb_rf.score(X_train,y_train),2))\n",
    "print('Test Accuracy score: ',round(xgb_rf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = xgb_rf.predict(X_test)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, xgb_rf, expt_name='Test B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CatBoost with Final Call Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics_summary = pd.DataFrame()\n",
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary\n",
    "#test = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "# test\n",
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C - Catboost + Final Call Type\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U catboost\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier()\n",
    "clf.fit(X_train,y_train,logging_level='Silent')\n",
    "print('Training score: ' ,round(clf.score(X_train,y_train),2))\n",
    "print('Test score: ',round(clf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, clf, expt_name='Test C')\n",
    "\n",
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Catboost with Initial Call Type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D - Catboost + Initial Call Type\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_split = df.drop(columns = 'Final Call Re-map')\n",
    "#category_cols = df_to_split.columns\n",
    "#target_col = ['Stop Resolution']\n",
    "#df_to_split = pd.DataFrame()\n",
    "#  Use the dataframe calculated in Test A\n",
    "\n",
    "initial_call_df_to_split = df.drop(columns = ['Final Call Re-map', 'Stop Resolution'])\n",
    "\n",
    "X = pd.get_dummies(initial_call_df_to_split,)# drop_first=True)   \n",
    "\n",
    "\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier()\n",
    "clf.fit(X_train,y_train,logging_level='Silent')\n",
    "print('Training score: ' ,round(clf.score(X_train,y_train),2))\n",
    "print('Test score: ',round(clf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, clf, expt_name='Test D')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SMOTE + Best of Others\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E - SMOTE + Catboost + Final Call\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn\n",
    "# Use the final_call dataframe calculated earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shouldn't need the y, because we can re-use if from above.  But just in case\n",
    "#y = df['Stop Resolution']\n",
    "#y.dtypes\n",
    "\n",
    "X = pd.get_dummies(final_call_df_to_split, )#drop_first=True)\n",
    "    \n",
    "\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = CatBoostClassifier()\n",
    "clf.fit(X_train,y_train,logging_level='Silent')\n",
    "print('Training score: ' ,round(clf.score(X_train,y_train),2))\n",
    "print('Test score: ',round(clf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, clf, expt_name='Test E')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. SMOTE + XGB + Final Call\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The SMOTED data on XBG-RF,  just for fun\n",
    "xgb_rf = XGBRFClassifier()\n",
    "xgb_rf.fit(X_train, y_train)\n",
    "print('Training score: ' ,round(xgb_rf.score(X_train,y_train),2))\n",
    "print('Test score: ',round(xgb_rf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = xgb_rf.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test, X_test, xgb_rf)\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, xgb_rf, expt_name='Test F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. SMOTE + SVM + Final Call Type\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a Support Vector Machine,  for the heck of it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC,LinearSVC,NuSVC\n",
    "clf = SVC()\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat_test = clf.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test,X_test,clf)\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, xgb_rf, expt_name='Test G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. SMOTENC + CatBoost + Final Call Type\n",
    "\n",
    "* **SMOTENC is a version of SMOTE specifically for continuous and categorical features.**<br><br>\n",
    "\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    -**H = SMOTENC + Catboost + Final Call Type**\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "    \n",
    "    \n",
    "   ** Experiment H and J are abandoned because even using the \n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_to_split = cat_df.drop(columns = ['Initial Call Re-map', 'Stop Resolution'])\n",
    "category_cols = cat_df_to_split.columns\n",
    "category_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cat_df_to_split\n",
    "y = cat_df['Stop Resolution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train\n",
    "\n",
    "X_temp = X_train.copy().drop(columns = ['Officer Gender', 'Subject Perceived Gender', 'Weekday', 'Time of Month', 'Watch'],)\n",
    "X_temp.astype('category')\n",
    "X_train_cat = X_temp.astype('category')\n",
    "X_train_cat['Officer Gender'] = X_train['Officer Gender']\n",
    "X_train_cat['Subject Perceived Gender'] = X_train['Subject Perceived Gender']\n",
    "X_train_cat['Weekday'] = X_train['Weekday']\n",
    "X_train_cat['Time of Month'] = X_train['Time of Month']\n",
    "X_train['Watch'].astype(int)\n",
    "X_train_cat['Watch'] = X_train['Watch']\n",
    "X_train_cat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now modify the training data by oversampling (SMOTENC)\n",
    "\n",
    "# Try Categorical SMOTE\n",
    "#\n",
    "\n",
    "smote_nc = SMOTENC(categorical_features = [0,1,2,3,4,5,6,7,8])\n",
    "\n",
    "X_train, y_train = smote_nc.fit_sample(X_train_cat, y_train)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = CatBoostClassifier()\n",
    "clf.fit(X_train,y_train,cat_features = [0,1,2,3,4,5,6,7,8], logging_level='Silent')\n",
    "print('Training score: ' ,round(clf.score(X_train,y_train),2))\n",
    "print('Test score: ',round(clf.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test,X_test,clf)\n",
    "#metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, xgb_rf, expt_name='Test H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_test, y_hat_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.concat([X, y], axis=1).corr().loc['Stop Resolution']\n",
    "importance.plot(kind='barh', figsize=(10,24));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson = pd.concat([y,X], axis=1)#.corr(method = 'pearson')\n",
    "pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation matrix to see the autocorrelated variables and plot it ou\n",
    "# Will run the correlation matrix for the last kernel run\n",
    "\n",
    "   \n",
    "pearson = pd.concat([y,X], axis=1).corr(method = 'pearson')\n",
    "\n",
    "sns.set(rc={'figure.figsize':(20,12)})\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(pearson)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "ax = sns.heatmap(data=pearson, mask=mask, cmap=\"YlGnBu\", \n",
    "                 annot=False, square=True, cbar_kws={'shrink': 0.5})\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. CBC-search + Final Call Type with or without SMOTENC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE + CBC-Search + Final Call type\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = SMOTE + CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_to_split5 = pd.DataFrame()\n",
    "#no need to re-calculate\n",
    "#final_call_df_to_split = df.drop(columns = ['Initial Call Re-map','Stop Resolution'])\n",
    "#X = pd.get_dummies(final_call_df_to_split, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_call_df_to_split.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(final_call_df_to_split, drop_first=True)\n",
    "category_cols = X.columns\n",
    "category_cols\n",
    "\n",
    "# not needed y = df['Stop Resolution']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "X_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "category_cols = X.columns\n",
    "train_pool =  Pool(data=X_train, label=y_train, cat_features=category_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test,  cat_features=category_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_base = CatBoostClassifier(iterations=500, depth=12,\n",
    "                            boosting_type='Ordered',\n",
    "                            learning_rate=0.03,\n",
    "                            thread_count=-1,\n",
    "                            eval_metric='AUC',\n",
    "                            silent=True,\n",
    "                            allow_const_label=True)#,\n",
    "                           #task_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_base.fit(train_pool,eval_set=test_pool, plot=True, early_stopping_rounds=10)\n",
    "cb_base.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score: ' ,round(cb_base.score(X_train,y_train),2))\n",
    "print('Test score: ',round(cb_base.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = cb_base.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test,X_test,cb_base)\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, cb_base, expt_name='Test I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(cb_base.feature_importances_, index = X.columns)\n",
    "importance.rename(columns = {0: \"Importance\"}, inplace = True)\n",
    "importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance1 = pd.Series(cb_base.feature_importances_, index = X.columns)\n",
    "importance1.sort_values(ascending = False, inplace = True)\n",
    "top_features1 = importance1.head(10).index\n",
    "importance2 = pd.concat([X,y], axis=1)[[*top_features1, 'Stop Resolution']].corr().loc['Stop Resolution']\n",
    "importance2.drop('Stop Resolution',inplace = True)\n",
    "importance2\n",
    "importance2.plot(kind = 'barh',);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J. SMOTENC  + CBC-search + Final Call type\n",
    "\n",
    " * **The Next Steps will be a set of experiments to look how the models can improve based on:**\n",
    "    - [1] Feature Selection:  Initial Call Type Versus Final Call Type \n",
    "    - [2] Model type:  XGBoost-RF  vs CatBoost\n",
    "    - [3] Balancing the dataset from best model of [1] and [2] using either SMOTE or SMOTENC. SmoteNC is an algorithm specifically developed for categorical and continuous 9variables. <br><br>\n",
    "    \n",
    "* **The Next Experiment will be (Bold Type):** <br><br>\n",
    "\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the same approach, with SMOTENC first\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_to_split = cat_df.drop(columns = ['Initial Call Re-map', 'Stop Resolution'])\n",
    "category_cols = cat_df_to_split.columns\n",
    "category_cols\n",
    "\n",
    "y = df['Stop Resolution']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)# stratify=y)#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTENC Bug - doesn't work with all categorical data\n",
    "\n",
    "** Below is a \"workaround\" described in Github, which also doesn't work, see the link **<br><br>\n",
    "\n",
    "X[\"temp\"] = 0\n",
    "n_features = X.shape[1] - 1\n",
    "n_features, X\n",
    "\n",
    "indices = range(n_features)\n",
    "print(indices)\n",
    "smote_nc = SMOTENC(categorical_features = indices)\n",
    "X_resampled, y_resampled = smote_nc.fit_sample(X_train, y_train)\n",
    "\n",
    "X_resampled.drop(columns = 'temp', inplace = True)\n",
    "    \n",
    "#display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n",
    "X_resampled\n",
    "\n",
    "#### According to a PR in Github, SMOTENC cannot work if all columns are categorical\n",
    "#### https://github.com/scikit-learn-contrib/imbalanced-learn/issues/562\n",
    "#### For now use 1 hot encoding and SMOTE.  Forget about SMOTENC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_call_df_to_split = df.drop(columns = ['Initial Call Re-map', 'Stop Resolution'])\n",
    "#X = pd.get_dummies(final_call_df_to_split, drop_first=True)\n",
    "\n",
    "#y = df['Stop Resolution']\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "#                                                    random_state=42,)#stratify=y)#\n",
    "\n",
    "#smote_nc = SMOTENC(categorical_features = [0,1,3,4,6,9,11])\n",
    "\n",
    "X_train, y_train = smote_nc.fit_sample(X_train, y_train)\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category_cols = X.columns\n",
    "\n",
    "train_pool =  Pool(data=X_train, label=y_train, cat_features=category_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test,  cat_features=category_cols)\n",
    "cb_base = CatBoostClassifier(iterations=500, depth=12,\n",
    "                            boosting_type='Ordered',\n",
    "                            learning_rate=0.03,\n",
    "                            thread_count=-1,\n",
    "                            eval_metric='AUC',\n",
    "                            silent=True,\n",
    "                            allow_const_label=True)#,\n",
    "                           #task_type='GPU')\n",
    "\n",
    "cb_base.fit(train_pool,eval_set=test_pool, plot=True, early_stopping_rounds=10)\n",
    "cb_base.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score: ' ,round(cb_base.score(X_train,y_train),2))\n",
    "print('Test score: ',round(cb_base.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = cb_base.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test,X_test,cb_base)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, cb_base, expt_name='Test J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary_t = metrics_summary.transpose()\n",
    "metrics_summary_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(cb_base.feature_importances_)\n",
    "importance #= pd.drop(rows = 'Stop Resolution')\n",
    "#importance = pd.Series(cb_base.feature_importances_, index = X.columns)\n",
    "#importance.sort_values(ascending = True, inplace = True)\n",
    "#top_features = importance.head(10).index\n",
    "#importance = pd.concat([X,y], axis=1)[[*top_features, 'Stop Resolution']].corr().loc['Stop Resolution']\n",
    "#importance.plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.  Calculate the correlation between the top features found by CatBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use SMOTENC with CATBOOST Built-in Features\n",
    "\n",
    " ** \n",
    "     - [x]  1-hot encoding built-in (pass in categoricals\n",
    "     - [x]  Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_to_split = df.drop(columns = ['Initial Call Re-map', 'Stop Resolution'])\n",
    "#category_cols = df_to_split.columns\n",
    "\n",
    "\n",
    "# Convert catogories to cat.codes\n",
    "#X = pd.get_dummies(final_call_df_to_split, drop_first=True)\n",
    "\n",
    "#y = df['Stop Resolution']\n",
    "\n",
    "#for header in category_cols:\n",
    "#    df_to_split[header] = df[header].astype('category').cat.codes\n",
    "    \n",
    "\n",
    "X_train, X_test, y_train,y_test  = train_test_split(X,y,test_size=.3,\n",
    "                                                    random_state=42,)#stratify=y)#\n",
    "\n",
    "smote_nc = SMOTENC(categorical_features = [0,11])\n",
    "X_train, y_train = smote_nc.fit_sample(X_train, y_train)\n",
    "\n",
    "display(y_train.value_counts(normalize=False),y_test.value_counts(normalize=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = X.columns\n",
    "train_pool =  Pool(data=X_train, label=y_train, cat_features=category_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test,  cat_features=category_cols)\n",
    "cb_base = CatBoostClassifier(iterations=500, depth=12,\n",
    "                            boosting_type='Ordered',\n",
    "                            learning_rate=0.03,\n",
    "                            thread_count=-1,\n",
    "                            eval_metric='AUC',\n",
    "                            silent=True,\n",
    "                            allow_const_label=True)#,\n",
    "                           #task_type='GPU')\n",
    "\n",
    "cb_base.fit(train_pool,eval_set=test_pool, plot=True, early_stopping_rounds=10)\n",
    "cb_base.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training score: ' ,round(cb_base.score(X_train,y_train),2))\n",
    "print('Test score: ',round(cb_base.score(X_test,y_test),2))\n",
    "\n",
    "y_hat_test = cb_base.predict(X_test)\n",
    "\n",
    "#evaluate_model(y_test,y_hat_test,X_test,cb_base)\n",
    "\n",
    "metrics_df, comps = evaluate_model(y_test,y_hat_test, X_test, cb_base, expt_name='Test J')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_summary = pd.concat([metrics_summary, metrics_df], axis = 1)\n",
    "metrics_summary_t = metrics_summary.transpose()\n",
    "metrics_summary_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = pd.merge(comparison,comps, left_index = True, right_index=True)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions on ML Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following experiments were performed:\n",
    "\n",
    "* The data set is one-hot encoded, prior to modelling <br><br>\n",
    "\n",
    "\n",
    "    - A = Vanilla Model = XBG + Initial Call Type\n",
    "    - B = XBG + Final Call Type\n",
    "    - C = Catboost + Initial Call Type\n",
    "    - D = Catboost + Final Call Type\n",
    "    - E = SMOTE + Catboost + Final Call Type\n",
    "    - F = SMOTE + XGB + Final Call Type\n",
    "    - G = SMOTE + SVM + Final Call Type\n",
    "    - H = SMOTENC + Catboost + Final Call Type\n",
    "    - I = CBC-search + Final Call Type\n",
    "    - J = SMOTENC + CBC-search + Final Call Type\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "    \n",
    " - [x] Which features are best:  There was a clear improvement in the prediction(several % more accuracy) when  \"Final Call Type\" was used versus \"Initial Call Type\". Reasons could be a) human difficulties to encode the rather cryptic call text, coming in initial calls from 911. For initial calls I found it difficult to determine the correct code assignment,  for ~500 samples.  In contrast the final call type was more well behaved, probably because officers can re-code the call fairly uniformly. (4-8% improvement!)\n",
    " \n",
    " - [x] CatBoost was a better algorithm than XGB-RF and SVM, presumably because it is a better classifer for all categorical data,  which I had. (1-3% improvement)\n",
    " \n",
    " - [x] Correcting imbalances in the samples using SMOTE and SMOTENC (for categoricals), helped improve the false negatives with similar accuracy.(1-2% improvement)\n",
    " \n",
    " - [x] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The key concept is that in training we know that the some precincts are more successful than others at getting to an arrest.  Instead of imputed a 1-hot encoded value,  use the percentage of successful arrests as the values for the precinct.\n",
    "\n",
    "#Calculate how successful particular precincts were at making arrests\n",
    "\n",
    "arrest_percentage = arrest_df['Precinct'].value_counts() / df['Precinct'].value_counts()\n",
    "print(f'The percentage of arrests based on terry stops, by squad \\n\\n',arrest_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a dictionary for mapping the squads which have successful arrest.  Those officer squads which have <br><br>\n",
    "### reported Terry stops with no arrests will be dropped from the dataset\n",
    "successful_arrest_map=arrest_percentage.to_dict()\n",
    "\n",
    "### successful_arrest_map # Take a look at the dictionary\n",
    "\n",
    "df['Precinct Success']=df['Precinct'].map(successful_arrest_map) # map the dictionary to the dataframe with a new column3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Perform the same analysis to see which call types lead to more arrests\n",
    "\n",
    "arrest_df = df.loc[df['Stop Resolution'] == 'Arrest'] # Re-Create the arrest_df in case there were removals earlier\n",
    "arrest_df['Final Call Type'].value_counts(),  df['Final Call Type'].value_counts()\n",
    "\n",
    "arrest_categories = arrest_df['Final Call Type'].value_counts() / df['Final Call Type'].value_counts() \n",
    "arrest_map = arrest_categories.to_dict()\n",
    "arrest_map # look at the dictionary '''\n",
    "\n",
    "#df['Final Call Success'] = df['Final Call Type'].map(arrest_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Create dataframe eval_df and metrics_df to hold the values from each model\n",
    "eval_df = pd.DataFrame(\n",
    "          [[\"Model\", \"XGB\", \"XGB\", \"CATBOOST\", \"CATBOOST\", \"SMOTE + CB\", \"SMOTE + XGB\", \"SMOTE+1hot+CB\", \n",
    "          \"SMOTE+CBC\", \"SMOTE+1hot+CBC\"], ['Feature', 'Initial Call Type', 'Final Call Type', \n",
    "         'Final Call Type', 'Initial Call Type', 'Final Call Type', 'Final Call Type', 'Final Call Type', \n",
    "         'Final Call Type', \"Final Call Type\"], ['Encoding', 'Categorical', 'Categorical', 'Categorical', \n",
    "         'Categorical','Categorical', 'Categorical','1 Hot', 'Categorical', '1 Hot'], ['SMOTE', 'No', 'No', 'No', 'No', \n",
    "         'Yes', 'Yes', 'Yes', 'No', 'Yes']], index = [1,2,3,4], columns=['Description','Test A', \n",
    "         'Test B','Test C', 'Test D', 'Test E', 'Test F', 'Test G', 'Test H', 'Test I',])\n",
    "\n",
    "eval_df.head()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key references:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "\n",
    "\n",
    "* https://assets.documentcloud.org/documents/6136893/SPDs-2019-Annual-Report-on-Stops-and-Detentions.pdf <br><br>\n",
    "\n",
    "* https://www.seattletimes.com/seattle-news/crime/federal-monitor-finds-seattle-police-are-conducting-proper-stops-and-frisks/ <br> <br>\n",
    "* https://catboost.ai/docs/concepts/python-reference_catboost_grid_search.html<br><br>\n",
    "* https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "694.5px",
    "left": "50px",
    "top": "110.114px",
    "width": "261.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
